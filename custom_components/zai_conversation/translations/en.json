{
  "config": {
    "step": {
      "user": {
        "title": "Connect to z.ai",
        "description": "Enter your z.ai API credentials",
        "data": {
          "api_key": "API Key",
          "base_url": "Base URL"
        }
      }
    },
    "error": {
      "authentication_error": "Invalid API key",
      "cannot_connect": "Cannot connect to z.ai",
      "timeout_connect": "Connection timeout",
      "unknown": "Unknown error occurred"
    },
    "abort": {
      "already_configured": "z.ai is already configured"
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Configure z.ai Conversation Agent",
        "description": "Configure your z.ai conversation agent",
        "data": {
          "personality": "Personality",
          "memory_enabled": "Enable Memory",
          "use_custom_prompt": "Use Optimized Prompt",
          "prompt": "Additional Instructions",
          "output_language": "Output Language",
          "llm_hass_api": "Control Home Assistant",
          "recommended": "Use recommended settings"
        },
        "data_description": {
          "personality": "Choose the assistant's communication style",
          "memory_enabled": "Remember user preferences and notes across sessions",
          "use_custom_prompt": "Use optimized prompt with device list and tool instructions",
          "prompt": "Additional custom instructions (optional)",
          "output_language": "Language for assistant responses",
          "llm_hass_api": "Allow the integration to control Home Assistant"
        }
      },
      "advanced": {
        "title": "Advanced Configuration",
        "description": "Configure advanced options",
        "data": {
          "chat_model": "Model",
          "max_tokens": "Maximum Tokens",
          "temperature": "Temperature",
          "area_filter": "Limit to Areas"
        },
        "data_description": {
          "chat_model": "The GLM model to use for conversation",
          "max_tokens": "Maximum number of tokens to generate",
          "temperature": "Sampling temperature (0-1). Lower = more consistent",
          "area_filter": "Only include devices from these areas (empty = all)"
        }
      }
    }
  },
  "selector": {
    "personality": {
      "options": {
        "formal": "Formal",
        "friendly": "Friendly",
        "concise": "Concise"
      }
    },
    "output_language": {
      "options": {
        "en": "English",
        "fr": "Français",
        "it": "Italiano",
        "de": "Deutsch",
        "es": "Español"
      }
    }
  },
  "subentry": {
    "conversation": {
      "step": {
        "init": {
          "title": "Configure z.ai Conversation Agent",
          "description": "Configure your z.ai conversation agent",
          "data": {
            "name": "Name",
            "personality": "Personality",
            "memory_enabled": "Enable Memory",
            "use_custom_prompt": "Use Optimized Prompt",
            "prompt": "Additional Instructions",
            "output_language": "Output Language",
            "llm_hass_api": "Control Home Assistant",
            "recommended": "Use recommended settings"
          },
          "data_description": {
            "personality": "Choose the assistant's communication style",
            "memory_enabled": "Remember user preferences and notes across sessions",
            "use_custom_prompt": "Use optimized prompt with device list and tool instructions",
            "prompt": "Additional custom instructions (optional)",
            "output_language": "Language for assistant responses",
            "llm_hass_api": "Allow the integration to control Home Assistant"
          }
        },
        "advanced": {
          "title": "Advanced Configuration",
          "description": "Configure advanced options",
          "data": {
            "chat_model": "Model",
            "max_tokens": "Maximum Tokens",
            "temperature": "Temperature",
            "area_filter": "Limit to Areas"
          },
          "data_description": {
            "chat_model": "The GLM model to use for conversation",
            "max_tokens": "Maximum number of tokens to generate",
            "temperature": "Sampling temperature (0-1). Lower = more consistent",
            "area_filter": "Only include devices from these areas (empty = all)"
          }
        }
      }
    }
  }
}
